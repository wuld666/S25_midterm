{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 (18 pts)\n",
    "## Applied AI/Machine Learning (ITSS 4382)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#ccc'>**PART A:** Answer the MCQ Q1-Q12.</font><br>\n",
    "<font color='red'>**PART B:** Answer the following questions and write your own code/answers in the boxes below. (A Jupyter Notebook simulator is available below as a courtesy tool for you to test and debug your answer.)</font>\n",
    "\n",
    "In this part, you are required to provide your answers and code in one of the following ways:\n",
    "\n",
    "1. **Direct Submission:** Write your code and responses in the designated cells provided below each question.\n",
    "2. **Notebook Submission:** Alternatively, download this file as a .ipynb file, complete your responses, and submit your compiled .ipynb file to eLearning via [this link](https://elearning.utdallas.edu/webapps/assignment/uploadAssignment?content_id=_8884199_1&course_id=_383685_1&group_id=&mode=cpview).\n",
    "\n",
    "\n",
    "This assignment covers a set of Regression models in Supervised Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# packages for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Models\n",
    "\n",
    "In this part, you are required to analyze the daily version of the [Capital Bikeshare System dataset](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset) from the UCI Machine Learning Repository. This data set contains information about the daily count of bike rental checkouts in Washington, D.C.’s bikeshare program between 2011 and 2012. It also includes information about the weather and seasonal/temporal features for that day (e.g., if it was a weekday).\n",
    "- **day:** Day of the record (relative to day 1: 2011-01-01)\n",
    "- **season:** Season (1: spring, 2: summer, 3: fall, 4: winter)\n",
    "- **weekday:** Day of the week (0 = Sunday, 6 = Saturday)\n",
    "- **workingday:** 1 if the day is neither a weekend nor a holiday, otherwise 0.\n",
    "- **weathersit:** Weather condition categories<br>\n",
    "    - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "    - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "    - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered\n",
    "clouds\n",
    "- **temp:** Normalized temperature in Celsius\n",
    "- **windspeed:** Normalized wind speed\n",
    "- **casual:** Count of checkouts by casual/non-registered users\n",
    "- **registered:** Count of checkouts by registered users\n",
    "- **cnt:** Total count of bike rentals (Target Variable)\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "Load the dataset and inspect its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = pd.read_csv(\"day.csv\")\n",
    "print(day.columns.values) # to find variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# heatmap on selected columns\n",
    "sns.heatmap(day[['weekday', 'season','workingday', 'temp', 'windspeed', 'weathersit', 'cnt']].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1a |  Show the top 10 records in the dataset. (1 pts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1b | Show the total number of records in the dataset. (1 pts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split\n",
    "\n",
    "We will use features ('weekday', 'season','workingday', 'temp', 'windspeed', 'weathersit') to predict the checkout counts. We are interested in predicting the total checkout counts ('cnt')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['weekday', 'workingday', 'temp', 'windspeed', 'season', 'weathersit']\n",
    "X = day[var]\n",
    "y = day['cnt']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 | Basic Linear Regression (3 pts)\n",
    "\n",
    "- Train a linear model. Let X be ['weekday', 'workingday', 'temp', 'windspeed', 'season', 'weathersit']. Let y be 'cnt'. \n",
    "- Report the coefficients of variables (no need to report the intercept).\n",
    "- Report the R^2 score and mse on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 | Linear Model with Polynomial Feature (4 pts) \n",
    "\n",
    "- Using the above splitted dataset, create polynomial features with a degree of 3. \n",
    "- Train linear regression on transformed data.\n",
    "- Report the R^2 score and MSE on the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4a | Pipeline (4 pts) \n",
    "\n",
    "A **Pipeline** streamlines the machine learning workflow by chaining multiple steps (e.g., preprocessing, modeling) into a single object. Write a pipeline to train an efficient linear model with scaled data.\n",
    "\n",
    "- Using the above splitted dataset, create polynomial features with a degree of 3. \n",
    "- Train linear regression on transformed data.\n",
    "- Report the R^2 score and MSE on the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4b | R^2 score (1 pts) \n",
    "\n",
    "- Manually set the polynomial feature degree to 4 and rerun your code from Q4a with this updated polynomial degree.\n",
    "- Based on the model's performance (e.g., R² score on both the training and test sets), explain whether overfitting occurred.\n",
    "- Justify your conclusion by comparing the R² scores and identifying signs of potential overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maximum 3 sentences**\n",
    "\n",
    "<br><br>\n",
    "#### WRITE YOUR ANSWER HERE\n",
    "<br><br><br><br><br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 | Hyperparameter Tuning Using GridSearchCV (4 pts)\n",
    "\n",
    "GridSearchCV helps automate the hyperparameter tuning process by performing an exhaustive search over specified parameter values.\n",
    "\n",
    "- Use GridSearchCV to search for the best polynomial degree in (1 to 5), where 5 is not included.\n",
    "- Use a Pipeline to combine polynomial feature generation, data scaling, and linear regression.\n",
    "- After training the model, identify the best polynomial degree.\n",
    "- Report the best parameters and the best R^2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
